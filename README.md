Voice disorders affect the quality and stability of speech and are often associated with irregular vocal fold vibrations. Acoustic features such as jitter and shimmer are widely used to quantify these irregularities, as they capture variations in fundamental frequency and amplitude, respectively.

This project focuses on classifying voice disorders using jitter and shimmer features extracted from speech signals. By analyzing these perturbation measures, the system aims to distinguish between healthy and pathological voices. Machine learning models are trained on the extracted features to automatically identify patterns indicative of vocal abnormalities.

The proposed approach demonstrates how simple yet clinically relevant acoustic features can be effectively used for voice disorder detection, with potential applications in early diagnosis, clinical decision support, and speech pathology research.
